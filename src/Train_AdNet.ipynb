{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Train_AdNet.ipynb",
      "provenance": [],
      "collapsed_sections": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "sDTRAg38ff5M"
      },
      "source": [
        "# Importing Libraries"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "GflsWJ8l7Myl"
      },
      "source": [
        "import tensorflow as tf\n",
        "import numpy as np\n",
        "import cv2\n",
        "import os\n",
        "from google.colab.patches import cv2_imshow\n",
        "import random\n",
        "import keras\n",
        "import sys\n",
        "from keras.layers import Lambda, Flatten, Dense, Layer, ConvLSTM2D, Input, Dropout\n",
        "from keras.models import Sequential, Model\n",
        "import matplotlib.pyplot as plt\n",
        "%matplotlib inline"
      ],
      "execution_count": 16,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "59KrSBMgfofX"
      },
      "source": [
        "# Video Generator"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "E8sFWXILgRVB"
      },
      "source": [
        "class VideoGenerator:\n",
        "  '''\n",
        "    for generating triplets required for loss function\n",
        "\n",
        "    Parameters:\n",
        "      'path': str\n",
        "        path to main folder containing subfolders of videos of each class in their separate folder\n",
        "      \n",
        "      'seq_len': int\n",
        "        number of frames to be picked from each video. total frames = seq_len + 1\n",
        "      \n",
        "      'resize' : tuple (width, height)\n",
        "        frame will be resized to this shape\n",
        "\n",
        "      'batch': int\n",
        "        number of videos in each batch\n",
        "\n",
        "      'split_ratio' : tuple of int or float (train_size_percent, valid_size_percent, test_size_percent) Default = (60,20,20) (optional)\n",
        "        ratio in which data will be split. The sum of the values must be equal to 100. \n",
        "\n",
        "    '''\n",
        "  def __init__(self, path, seq_len, resize, split_ratio=(60,20,20)):\n",
        "    self.path = path\n",
        "    self.classes = [c for c in os.listdir(self.path) if c[0]!='.']\n",
        "    self.classes.sort()\n",
        "    \n",
        "    self.noOfClasses = -1\n",
        "    self.class_label =[]\n",
        "    self.seq_len =seq_len\n",
        "    self.resize =resize\n",
        "    self.noOfTriplets = 0\n",
        "    self.data = []\n",
        "    self.generate_paths_triplet()\n",
        "\n",
        "    #Splits the dataset\n",
        "    if len(split_ratio) != 3:\n",
        "      sys.exit(\"Invalid Values provided for parameter 'split_ratio'. It can take can only three values as tuple (train, valid, test)\")\n",
        "    \n",
        "    elif np.sum(split_ratio) != 100:\n",
        "      sys.exit(\"Invalid Values provided for parameter 'split_ratio'. train, valid and test must add up to 100.\")\n",
        "    \n",
        "    else:\n",
        "      self.train_data, self.valid_data, self.test_data = self.SplitData(split_ratio)\n",
        "\n",
        "  def SplitData(self, split_ratio):\n",
        "      '''\n",
        "      Splits the dataset and returns training, validation and test dataset, each as tuple of (data, labels):\n",
        "      \n",
        "      Parameters:\n",
        "      \n",
        "      'split_ratio' : tuple of int or float (train_size_percent, valid_size_percent, test_size_percent)\n",
        "            ratio in which data will be split. The sum of the values must be equal to 100. \n",
        "      \n",
        "      '''\n",
        "      #Shuffle data    \n",
        "      np.random.shuffle(self.data)\n",
        "      \n",
        "      #Split data\n",
        "      train_data, valid_data, test_data = np.split(self.data, [int((split_ratio[0]/100)*len(self.data)), int(((split_ratio[0]+split_ratio[1])/100)*len(self.data))])\n",
        "        \n",
        "      return train_data, valid_data, test_data\n",
        "\n",
        "  def generate_random_number (self, low, high):\n",
        "    '''\n",
        "    retrun random integer number between low and high.\n",
        "    \n",
        "    Parameters:\n",
        "      'low': int (inclusive)\n",
        "      'high':int (exlcusive)\n",
        "    '''\n",
        "    return np.random.randint(low, high)\n",
        "\n",
        " \n",
        "  def generate_paths_triplet(self):\n",
        "    ''' \n",
        "    Generator : generates paths to triplets as (positive, anchor, positive) \n",
        "    '''\n",
        "    for index, label in enumerate(self.classes):\n",
        "      n=os.path.join (self.path, label)\n",
        "\n",
        "      videos = [vid for vid in os.listdir(n) if vid[0]!='.']\n",
        "\n",
        "      while len(videos) >=2:\n",
        "\n",
        "        #select anchor and positive video path\n",
        "        anchor = os.path.join(n, videos.pop(self.generate_random_number(0, len(videos))))\n",
        "        positive = os.path.join(n, videos.pop(self.generate_random_number(0, len(videos))))\n",
        "\n",
        "        #select negative video path\n",
        "        temp = self.classes [:]\n",
        "        temp.pop(index)\n",
        "\n",
        "        neg_label =temp[self.generate_random_number(0, len(temp))]\n",
        "\n",
        "        temp2 = [t for t in os.listdir(os.path.join(self.path, neg_label)) if t[0] != '.']\n",
        "\n",
        "        negative = os.path.join(os.path.join(self.path, neg_label), temp2[self.generate_random_number(0, len(temp2))])\n",
        "\n",
        "        self.data.append( [(positive, index), (anchor, index), (negative, self.classes.index(neg_label))])\n",
        "      \n",
        "      self.total_videos = len(self.data)\n",
        "  \n",
        "  def load_video (self, video_path):\n",
        "    '''\n",
        "      selects specific frames using 'seq_len' in a video, resizes it, maps it between 0 and 1 \n",
        "      and retruns the result as (seq_len, height, width, channel)\n",
        "\n",
        "\n",
        "    '''\n",
        "    video = np.zeros((self.seq_len+1, self.resize[1], self.resize[0], 3))\n",
        "    cap = cv2.VideoCapture(video_path)\n",
        "      \n",
        "    if (cap.isOpened()== False):\n",
        "      sys.exit(\"Error opening video\")\n",
        "    \n",
        "    #determine step size \n",
        "    noOfFrames = int(cap.get(cv2.CAP_PROP_FRAME_COUNT))\n",
        "    step = int(noOfFrames/self.seq_len)\n",
        "\n",
        "\n",
        "    if noOfFrames == 0:\n",
        "      self.noFrame_counter +=1\n",
        "    else:\n",
        "    \n",
        "      count =0 \n",
        "      while 1:\n",
        "\n",
        "        #read specific frames\n",
        "        cap.set(cv2.CAP_PROP_POS_FRAMES, step*count)\n",
        "        ret, frame =cap.read()\n",
        "        \n",
        "        if ret == False or count > self.seq_len:   \n",
        "          break\n",
        "        \n",
        "        else:\n",
        "          frame =cv2.resize(frame, self.resize)\n",
        "          video[count, :,:,:]=frame/255 #map between 0 and 1 values\n",
        "\n",
        "          count +=1  \n",
        "    return video\n",
        "\n",
        "  def generate_video(self, flag, batch):\n",
        "    '''\n",
        "    Generator: for batch of videos with shape (batch, 3, seq_len+1, height, width, channels)\n",
        "    and one hot encoded labels with shape(batch, total number of classes)\n",
        "    \n",
        "    Parameters:\n",
        "\n",
        "       'batch': int\n",
        "        number of videos in each batch\n",
        "      \n",
        "      'flag' : str = 'train', 'valid', or 'test'\n",
        "        Specifies from which dataset to load the images\n",
        "  '''\n",
        "\n",
        "    self.class_label =  [[c, i] for i, c in enumerate(self.classes)]\n",
        "    self.noOfClasses = len(self.classes)\n",
        "\n",
        "    self.noOfTriplets = 0\n",
        "    X_pos = np.zeros((batch, self.seq_len+1, self.resize[1], self.resize[0], 3))\n",
        "    X_anch = np.zeros((batch, self.seq_len+1, self.resize[1], self.resize[0], 3))\n",
        "    X_neg = np.zeros((batch, self.seq_len+1, self.resize[1], self.resize[0], 3))\n",
        "    Y = np.zeros((batch, 3))\n",
        "    self.noFrame_counter=0\n",
        "    \n",
        "    if flag == 'train':\n",
        "      triplets = self.train_data\n",
        "\n",
        "    elif flag == 'valid':\n",
        "      triplets = self.valid_data\n",
        "\n",
        "    elif flag == 'test':\n",
        "      triplets =self.test_data\n",
        "\n",
        "    else:\n",
        "      sys.exit(\"Invalid value provided for parameter 'flag'. It can either be 'train', 'valid' or 'test'\")\n",
        "    \n",
        "    while 1:\n",
        "      \n",
        "      for (positive, positive_label), (anchor, anchor_label), (negative, negative_label) in triplets:\n",
        "\n",
        "        X_pos[self.noOfTriplets, :,:,:,:]=self.load_video(positive)\n",
        "      \n",
        "        X_anch[self.noOfTriplets, :,:,:,:]=self.load_video(anchor)\n",
        "        \n",
        "        X_neg[self.noOfTriplets, :,:,:,:]=self.load_video(negative) \n",
        "        \n",
        "        #If no frame exist in a video, \n",
        "        if self.noFrame_counter != 0:\n",
        "          self.noOfTriplets -= 1\n",
        "          self.noFrame_counter = 0\n",
        "\n",
        "        \n",
        "        #generate and return batch of videos\n",
        "        if self.noOfTriplets == batch-1:\n",
        "          yield (X_pos, X_anch, X_neg), Y\n",
        "          self.noOfTriplets = 0\n",
        "          X_pos = np.zeros((batch, self.seq_len+1, self.resize[1], self.resize[0], 3))\n",
        "          X_anch = np.zeros((batch, self.seq_len+1, self.resize[1], self.resize[0], 3))\n",
        "          X_neg = np.zeros((batch, self.seq_len+1, self.resize[1], self.resize[0], 3))\n",
        "\n",
        "        else:\n",
        "          self.noOfTriplets +=1"
      ],
      "execution_count": 17,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "bAVpRSrEQujM"
      },
      "source": [
        "train = VideoGenerator('/content/drive/MyDrive/RefinedData', 10, (32,18))\n",
        "valid = VideoGenerator('/content/drive/MyDrive/RefinedData', 10, (32,18))\n",
        "test = VideoGenerator('/content/drive/MyDrive/RefinedData', 10, (32,18))\n"
      ],
      "execution_count": 18,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "kDNz_g4yf0UG"
      },
      "source": [
        "# Triplet Loss Function"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "L9dZ7YodQkNg"
      },
      "source": [
        "class TripletLossLayer(Layer):\n",
        "    def __init__(self, alpha, **kwargs):\n",
        "        self.alpha = alpha\n",
        "        super(TripletLossLayer, self).__init__(**kwargs)\n",
        "    \n",
        "    def triplet_loss(self, inputs):\n",
        "        positive, anchor, negative = inputs\n",
        "        p_dist = tf.keras.backend.sum(tf.keras.backend.square(anchor-positive), axis=-1)\n",
        "        n_dist = tf.keras.backend.sum(tf.keras.backend.square(anchor-negative), axis=-1)\n",
        "        return tf.keras.backend.sum(tf.keras.backend.maximum(p_dist - n_dist + self.alpha, 0), axis=0)\n",
        "    \n",
        "    def call(self, inputs):\n",
        "        loss = self.triplet_loss(inputs)\n",
        "        self.add_loss(loss)\n",
        "        return loss"
      ],
      "execution_count": 20,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "F-XO22a4f4Pg"
      },
      "source": [
        "# Model"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "smW98skPfzHI"
      },
      "source": [
        "input_shape = (10, 18,32, 3)"
      ],
      "execution_count": 21,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "drBWloL57DOP"
      },
      "source": [
        "positive = Input(input_shape, name='positive')\n",
        "anchor = Input(input_shape, name='anchor')\n",
        "negative = Input(input_shape, name='negative')\n",
        "\n",
        "model = Sequential()\n",
        "model.add(ConvLSTM2D(filters = 16, kernel_size = (3, 3), return_sequences = False, data_format = \"channels_last\", input_shape =input_shape))\n",
        "model.add(Flatten())\n",
        "model.add(Dense(1024, activation=\"relu\"))\n",
        "model.add(Dropout(0.5))\n",
        "model.add(Dense(256, activation=None ))\n",
        "model.add(Lambda(lambda x: tf.math.l2_normalize(x, axis=1)))\n",
        "\n",
        "#generate embeddings\n",
        "emb_pos = model(positive)\n",
        "emb_anch = model(anchor)\n",
        "emb_neg = model(negative)\n",
        "\n",
        "loss_layer = TripletLossLayer(0.2, name='triplet_loss_layer')([emb_pos, emb_anch, emb_neg])\n",
        "AdNet = Model(inputs=[positive, anchor, negative], outputs = loss_layer)"
      ],
      "execution_count": 22,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "QyMx9J3_gSWJ",
        "outputId": "15563bc5-ff23-474c-e8ea-dff164ff9174"
      },
      "source": [
        "model.summary()"
      ],
      "execution_count": 23,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Model: \"sequential_2\"\n",
            "_________________________________________________________________\n",
            "Layer (type)                 Output Shape              Param #   \n",
            "=================================================================\n",
            "conv_lst_m2d_2 (ConvLSTM2D)  (None, 16, 30, 16)        11008     \n",
            "_________________________________________________________________\n",
            "flatten_2 (Flatten)          (None, 7680)              0         \n",
            "_________________________________________________________________\n",
            "dense_3 (Dense)              (None, 1024)              7865344   \n",
            "_________________________________________________________________\n",
            "dropout_1 (Dropout)          (None, 1024)              0         \n",
            "_________________________________________________________________\n",
            "dense_4 (Dense)              (None, 256)               262400    \n",
            "_________________________________________________________________\n",
            "lambda_1 (Lambda)            (None, 256)               0         \n",
            "=================================================================\n",
            "Total params: 8,138,752\n",
            "Trainable params: 8,138,752\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ZqceNr5JLHFD",
        "outputId": "a48553e5-f097-44a2-ff29-432b642a3b70"
      },
      "source": [
        "AdNet.summary()"
      ],
      "execution_count": 24,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Model: \"model_1\"\n",
            "__________________________________________________________________________________________________\n",
            "Layer (type)                    Output Shape         Param #     Connected to                     \n",
            "==================================================================================================\n",
            "positive (InputLayer)           [(None, 10, 18, 32,  0                                            \n",
            "__________________________________________________________________________________________________\n",
            "anchor (InputLayer)             [(None, 10, 18, 32,  0                                            \n",
            "__________________________________________________________________________________________________\n",
            "negative (InputLayer)           [(None, 10, 18, 32,  0                                            \n",
            "__________________________________________________________________________________________________\n",
            "sequential_2 (Sequential)       (None, 256)          8138752     positive[0][0]                   \n",
            "                                                                 anchor[0][0]                     \n",
            "                                                                 negative[0][0]                   \n",
            "__________________________________________________________________________________________________\n",
            "triplet_loss_layer (TripletLoss ()                   0           sequential_2[0][0]               \n",
            "                                                                 sequential_2[1][0]               \n",
            "                                                                 sequential_2[2][0]               \n",
            "==================================================================================================\n",
            "Total params: 8,138,752\n",
            "Trainable params: 8,138,752\n",
            "Non-trainable params: 0\n",
            "__________________________________________________________________________________________________\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "dQPqOIACf7dD"
      },
      "source": [
        "# Training"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "_mobiwhXLWV6"
      },
      "source": [
        "AdNet.compile(optimizer=keras.optimizers.Adam(0.001))"
      ],
      "execution_count": 25,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "4bDrlFiU_I-A",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "0baa33c2-d935-4767-8806-32e1f5f1ade2"
      },
      "source": [
        "history = AdNet.fit(train.generate_video( 'train', 10 ), validation_data=valid.generate_video('valid', 10), steps_per_epoch=train.total_videos//10, epochs= 2, verbose=1 )"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Epoch 1/2\n",
            "10/10 [==============================] - ETA: 0s - loss: 2.2259 "
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "vtgs47R1lgD5"
      },
      "source": [
        "# Save Model"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "2IacJZgqliJq"
      },
      "source": [
        "AdNet.save('AdNet.h5')\n",
        "model.save('model.h5')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "3-wSd8yGf-jR"
      },
      "source": [
        "# Prediciton\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "TkA64wk9GoxF"
      },
      "source": [
        "results = model.predict(test.generate_video('test', 10))\n",
        "print(results)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Mmq3ZeCygjDa"
      },
      "source": [
        "# Learning Curves"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 214
        },
        "id": "Q4jazOg1DdPm",
        "outputId": "a2d2f715-a929-4bff-b551-b74d31a70ef1"
      },
      "source": [
        "plt.plot(history.history['loss'])\n",
        "plt.xlabel('epoch')\n",
        "plt.ylabel('loss')\n",
        "plt.show()"
      ],
      "execution_count": 19,
      "outputs": [
        {
          "output_type": "error",
          "ename": "NameError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-19-7fea393c92e0>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mplt\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mplot\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mhistory\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mhistory\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'loss'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      2\u001b[0m \u001b[0mplt\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mxlabel\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'epoch'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0mplt\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mylabel\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'loss'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0mplt\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshow\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mNameError\u001b[0m: name 'history' is not defined"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "rqhQmE2mhHkl"
      },
      "source": [
        "# Database"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "HpwsotbehxZS"
      },
      "source": [
        "  def load_video (seq_len, resize, video_path):\n",
        "    '''\n",
        "      selects specific frames using 'seq_len' in a video, resizes it, maps it between 0 and 1 \n",
        "      and retruns the result as (seq_len, height, width, channel)\n",
        "\n",
        "\n",
        "    '''\n",
        "    video = np.zeros((seq_len+1, resize[1], resize[0], 3))\n",
        "    cap = cv2.VideoCapture(video_path)\n",
        "      \n",
        "    if (cap.isOpened()== False):\n",
        "      sys.exit(\"Error opening video\")\n",
        "    \n",
        "    #determine step size \n",
        "    noOfFrames = int(cap.get(cv2.CAP_PROP_FRAME_COUNT))\n",
        "    step = int(noOfFrames/seq_len)\n",
        "\n",
        "\n",
        "    if noOfFrames == 0:\n",
        "      continue\n",
        "    else:\n",
        "    \n",
        "      count =0 \n",
        "      while 1:\n",
        "\n",
        "        #read specific frames\n",
        "        cap.set(cv2.CAP_PROP_POS_FRAMES, step*count)\n",
        "        ret, frame =cap.read()\n",
        "        \n",
        "        if ret == False or count > seq_len:   \n",
        "          break\n",
        "        \n",
        "        else:\n",
        "          frame =cv2.resize(frame, resize)\n",
        "          video[count, :,:,:]=frame/255 #map between 0 and 1 values\n",
        "\n",
        "          count +=1  \n",
        "    return video"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "PYENOMTYhHNP"
      },
      "source": [
        "#make folder\n",
        "!mkdir /content/drive/MyDrive/Database\n",
        "\n",
        "#store paths\n",
        "database = /content/drive/MyDrive/Database\n",
        "path ='/content/drive/MyDrive/RefinedData'\n",
        "\n",
        "\n",
        "for label in os.listdir(path):\n",
        "  \n",
        "  n=os.path.join(path, label)\n",
        "  \n",
        "  #pick random exmple from a class  \n",
        "  f = [vid for vid in os.listdir(n)]\n",
        "  x = np.random.randint(len(f))\n",
        "  example = os.path.join(n, f[x])\n",
        "\n",
        "  \n",
        "  out = model.predict(load_video(example))\n",
        "  \n",
        "  filename = database + '/' + label + '.npy'  \n",
        "  with open(filename, 'wb') as file:\n",
        " \n",
        "    np.save(file, out) #save feature vector"
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}